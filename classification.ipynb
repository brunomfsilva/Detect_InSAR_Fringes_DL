{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16, InceptionV3, ResNet50V2, InceptionResNetV2, Xception, VGG19\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import tensorflow as tfS\n",
    "from keras import backend as K\n",
    "import dill\n",
    " \n",
    "\n",
    "################################################\n",
    "#TREINAR MODELO\n",
    "######################################################\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)    \n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(  \n",
    "    train_dir,\n",
    "    target_size=(256,256),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(  \n",
    "    val_dir,\n",
    "    target_size=(256,256),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "\n",
    "\n",
    "#os.chdir('C:\\\\Users\\\\bmfs9\\\\Downloads\\\\TESE\\\\unw\\\\models\\\\teste')\n",
    "callb= [keras.callbacks.ModelCheckpoint(filepath='C:\\\\Users\\\\bmfs9\\\\Downloads\\\\TESE\\\\unw\\\\models\\\\teste\\\\FL2_vgg19_wra.h5', \n",
    "                                        monitor='val_loss', \n",
    "                                        save_best_only=True)]\n",
    "\n",
    "\n",
    "model.compile(loss=binary_focal_loss(gamma=2., alpha=.25),\n",
    "              optimizer=optimizers.Adam(lr=0.00001),\n",
    "              metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    #steps_per_epoch=260,\n",
    "    epochs=60,\n",
    "    validation_data=validation_generator,\n",
    "    #validation_steps=70,\n",
    "    callbacks=callb)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#criar plots\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(21, len(acc) + 21) #change to 1\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "dict_h=history.history\n",
    "\n",
    "###########################\n",
    "#Teste\n",
    "############################\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(256,256),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "\n",
    "model=load_model('C:\\\\Users\\\\bmfs9\\\\Downloads\\\\TESE\\\\unw\\\\models\\\\teste\\\\preliminary_tests\\\\vgg19.h5'#, \n",
    "                 #custom_objects={'binary_focal_loss_fixed': binary_focal_loss()} \n",
    "                 )\n",
    "\n",
    "teste= model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pastas\n",
    "train_dir= 'C:\\\\Users\\\\bmfs9\\\\Downloads\\\\TESE\\\\Dataset_patches_FL2\\\\wra\\\\train'\n",
    "val_dir= 'C:\\\\Users\\\\bmfs9\\\\Downloads\\\\TESE\\\\Dataset_patches_FL2\\\\wra\\\\validation'\n",
    "test_dir= 'C:\\\\Users\\\\bmfs9\\\\Downloads\\\\TESE\\\\Dataset_patches\\\\wra\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred:  A tensor resulting from a sigmoid\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        # Define epsilon so that the back-propagation will not result in NaN for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        # y_pred = y_pred + epsilon\n",
    "        # Clip the prediciton value\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        # Calculate p_t\n",
    "        p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        # Calculate alpha_t\n",
    "        alpha_factor = K.ones_like(y_true) * alpha\n",
    "        alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -K.log(p_t)\n",
    "        weight = alpha_t * K.pow((1 - p_t), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.mean(K.sum(loss, axis=1))\n",
    "        return loss\n",
    "\n",
    "    return binary_focal_loss_fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
